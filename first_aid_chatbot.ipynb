{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.stem import LancasterStemmer\n",
    "import nltk\n",
    "import numpy as np\n",
    "import random\n",
    "import json\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"intents.json\") as f:\n",
    "    data=json.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "words,labels=[],[]\n",
    "x_docs,y_docs=[],[]\n",
    "\n",
    "for intents in data[\"intents\"]:\n",
    "    for patterns in intents[\"patterns\"]:\n",
    "        wrds=nltk.word_tokenize(patterns)\n",
    "        words.extend(wrds)\n",
    "        x_docs.append(wrds)\n",
    "        y_docs.append(intents[\"tag\"])\n",
    "\n",
    "    if intents[\"tag\"] not in labels:\n",
    "        labels.append(intents[\"tag\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "stemmer=LancasterStemmer()\n",
    "words=[stemmer.stem(w.lower()) for w in words if w!=\"?\"]\n",
    "words=sorted(list(set(words)))\n",
    "labels=sorted(labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "training,output=[],[]\n",
    "output_data=[0 for i in range(len(labels))]\n",
    "\n",
    "for i,text in enumerate(x_docs):\n",
    "    bag=[]\n",
    "    wrds=[stemmer.stem(w.lower()) for w in text]\n",
    "    for w in words:\n",
    "        if w in wrds:\n",
    "            bag.append(1)\n",
    "\n",
    "        else:\n",
    "            bag.append(0)\n",
    "\n",
    "    output_row=output_data[:]\n",
    "    output_row[labels.index(y_docs[i])]=1\n",
    "\n",
    "    training.append(bag)\n",
    "    output.append(output_row)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "training=np.array(training)\n",
    "output=np.array(output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(188, 44)"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(114,)"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "training[1].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Dense"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "model=Sequential()\n",
    "model.add(Dense(units=100,activation=\"relu\",input_shape=training[1].shape))\n",
    "model.add(Dense(units=50,activation=\"relu\"))\n",
    "model.add(Dense(units=50,activation=\"relu\"))\n",
    "model.add(Dense(units=44,activation=\"softmax\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 188 samples\n",
      "Epoch 1/20\n",
      "188/188 [==============================] - 0s 532us/sample - loss: 3.7929 - acc: 0.0266\n",
      "Epoch 2/20\n",
      "188/188 [==============================] - 0s 170us/sample - loss: 3.7258 - acc: 0.0638\n",
      "Epoch 3/20\n",
      "188/188 [==============================] - 0s 186us/sample - loss: 3.6545 - acc: 0.1489\n",
      "Epoch 4/20\n",
      "188/188 [==============================] - 0s 175us/sample - loss: 3.5397 - acc: 0.2181\n",
      "Epoch 5/20\n",
      "188/188 [==============================] - 0s 165us/sample - loss: 3.3621 - acc: 0.2234\n",
      "Epoch 6/20\n",
      "188/188 [==============================] - 0s 186us/sample - loss: 3.0569 - acc: 0.3777\n",
      "Epoch 7/20\n",
      "188/188 [==============================] - 0s 186us/sample - loss: 2.6069 - acc: 0.5000\n",
      "Epoch 8/20\n",
      "188/188 [==============================] - 0s 181us/sample - loss: 2.0314 - acc: 0.7074\n",
      "Epoch 9/20\n",
      "188/188 [==============================] - 0s 198us/sample - loss: 1.4625 - acc: 0.8883\n",
      "Epoch 10/20\n",
      "188/188 [==============================] - 0s 181us/sample - loss: 0.9675 - acc: 0.9681\n",
      "Epoch 11/20\n",
      "188/188 [==============================] - 0s 181us/sample - loss: 0.6158 - acc: 0.9787\n",
      "Epoch 12/20\n",
      "188/188 [==============================] - 0s 170us/sample - loss: 0.3945 - acc: 1.0000\n",
      "Epoch 13/20\n",
      "188/188 [==============================] - 0s 176us/sample - loss: 0.2583 - acc: 1.0000\n",
      "Epoch 14/20\n",
      "188/188 [==============================] - 0s 186us/sample - loss: 0.1852 - acc: 1.0000\n",
      "Epoch 15/20\n",
      "188/188 [==============================] - 0s 181us/sample - loss: 0.1277 - acc: 1.0000\n",
      "Epoch 16/20\n",
      "188/188 [==============================] - 0s 176us/sample - loss: 0.0938 - acc: 1.0000\n",
      "Epoch 17/20\n",
      "188/188 [==============================] - 0s 186us/sample - loss: 0.0731 - acc: 1.0000\n",
      "Epoch 18/20\n",
      "188/188 [==============================] - 0s 197us/sample - loss: 0.0589 - acc: 1.0000\n",
      "Epoch 19/20\n",
      "188/188 [==============================] - 0s 197us/sample - loss: 0.0481 - acc: 1.0000\n",
      "Epoch 20/20\n",
      "188/188 [==============================] - 0s 192us/sample - loss: 0.0404 - acc: 1.0000\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x1f736653f70>"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.compile(optimizer=\"adam\",loss=\"categorical_crossentropy\",metrics=[\"accuracy\"])\n",
    "model.fit(training,output,epochs=20,batch_size=8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"data.pickle\",\"wb\") as f:\n",
    "    pickle.dump((words,labels,training,output),f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save(\"aid_chatbot.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "def bag_of_words(s,words):\n",
    "    bag=[0 for _ in range(len(words))]\n",
    "    s_words=nltk.word_tokenize(s)\n",
    "    s_words=[stemmer.stem(w.lower()) for w in s_words]\n",
    "\n",
    "    for se in s_words:\n",
    "        for i,w in enumerate(words):\n",
    "            if w==se:\n",
    "                bag[i]=1\n",
    "\n",
    "    return np.array(bag)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'To treat a fever at home: 1)Drink plenty of fluids to stay hydrated. 2)Dress in lightweight clothing. 3)Use a light blanket if you feel chilled, until the chills end. 4)Take acetaminophen (Tylenol, others) or ibuprofen (Advil, Motrin IB, others). 5) Get medical help if the fever lasts more than five days in a row.'"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "s=\"Please help me i have fever\"\n",
    "\n",
    "bag=bag_of_words(s,words)\n",
    "bag=np.reshape(bag,(1,bag.shape[0]))\n",
    "pred=model.predict([bag])\n",
    "tag=labels[np.argmax(pred)]\n",
    "\n",
    "for tg in data[\"intents\"]:\n",
    "    if tg[\"tag\"]==tag:\n",
    "        response=tg[\"responses\"]\n",
    "\n",
    "random.choice(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "247ab06e135bb35fa78c5eff31b2a9a0050dcb5fb773c2631d2a29ac689eeccb"
  },
  "kernelspec": {
   "display_name": "Python 3.9.7 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
